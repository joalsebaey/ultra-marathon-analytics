{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Ultra-Marathon Analytics – Data Transformation Pipeline\n**Project:** Ultra-Marathon Analytics Dashboard (PRD v3.0)  \n**Dataset:** TWO_CENTURIES_OF_UM_RACES.csv (~7M raw records → ~4.6M clean, 1996–2022)  \n**Pipeline stages:**\n1. Config\n2. Spark session\n3. Ingest & clean raw CSV\n4. Deduplication\n5. Gender / null filtering\n6. EDA\n7. Star-schema export (dim + fact tables)\n8. Pre-aggregated tables for Power BI\n\n> **Path convention** – all file I/O is driven by `BASE_DIR` in the config cell below.  \n> Change that one variable to move the pipeline to any machine or cloud storage location."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 0 · Configuration\nSet `BASE_DIR` once; every path is derived from it."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# ── Change this to your local or cloud storage root ─────────────────────────\nBASE_DIR = r\"C:/Users/youse/Dropbox/PC/Downloads/usa_ultra_marathon50km_mil_data\"\nRAW_CSV  = r\"C:/Users/youse/Dropbox/PC/Downloads/archive/TWO_CENTURIES_OF_UM_RACES.csv\"\n\n# ── Derived paths (no need to edit below) ───────────────────────────────────\nPATHS = {\n    \"raw_clean\":    os.path.join(BASE_DIR, \"ultra_marathon_clean_final.parquet\"),\n    \"deduped\":      os.path.join(BASE_DIR, \"ultra_marathon_clean_final_withoutduplicates.parquet\"),\n    \"final\":        os.path.join(BASE_DIR, \"fourmillion_fully_transformed_data.parquet\"),\n    \"dim_athletes\": os.path.join(BASE_DIR, \"dim_athletes.csv\"),\n    \"dim_events\":   os.path.join(BASE_DIR, \"dim_events.csv\"),\n    \"dim_date\":     os.path.join(BASE_DIR, \"dim_date.csv\"),\n    \"dim_distance\": os.path.join(BASE_DIR, \"dim_distance.csv\"),\n    \"dim_gender\":   os.path.join(BASE_DIR, \"dim_gender.csv\"),\n    \"fact_races\":   os.path.join(BASE_DIR, \"fact_races.parquet\"),\n    \"agg_yearly\":   os.path.join(BASE_DIR, \"agg_yearly.csv\"),\n    \"agg_country\":  os.path.join(BASE_DIR, \"agg_country.csv\"),\n    \"agg_seasonal\": os.path.join(BASE_DIR, \"agg_seasonality.csv\"),\n    \"agg_age\":      os.path.join(BASE_DIR, \"agg_age_performance.csv\"),\n    \"agg_elite\":    os.path.join(BASE_DIR, \"agg_elite_vs_avg.csv\"),\n}\n\nos.makedirs(BASE_DIR, exist_ok=True)\nprint(\"Config loaded. BASE_DIR:\", BASE_DIR)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1 · Spark Session\nRequires PySpark ≥ 4.1.1 (see `requirements.txt`)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "try:\n    spark.stop()\nexcept Exception:\n    pass\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n\nspark = (\n    SparkSession.builder\n    .appName(\"UltraMarathonCleaning\")\n    .config(\"spark.driver.memory\", \"8g\")\n    .config(\"spark.executor.memory\", \"4g\")\n    .config(\"spark.sql.shuffle.partitions\", \"100\")\n    .config(\"spark.driver.maxResultSize\", \"4g\")\n    .config(\"spark.network.timeout\", \"600s\")\n    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n    .getOrCreate()\n)\n\nprint(f\"PySpark version: {spark.version}\")\nprint(\"Spark session ready.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2 · Ingest & Clean\n**Steps performed:**\n- Load raw CSV, normalise column names (lowercase, underscores)\n- Strip BOM / invisible characters from `event_name`\n- Parse event dates (`dd.MM.yyyy`), distances (km & mi → km), and performance times (supports multi-day races)\n- Validate `birth_year` (1900–2005) and derive `athlete_age`\n- Validate `avg_speed_kmh` (physical ceiling: 0–25 km/h)\n- Filter: year 1950–2023, ages 16–90, finishers > 0, performance not null\n\n> **Dataset scope note:** The raw source covers 1950–2022 historically.  \n> Usable race data starts from **1996** — pre-1996 coverage is too sparse after filtering.  \n> See PRD §6 Known Limitations for context."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Ingest ──────────────────────────────────────────────────────────────────\ndf = spark.read.csv(RAW_CSV, header=True, inferSchema=True)\nprint(f\"Raw rows loaded: {df.count():,}\")\n\n# ── Normalise column names ───────────────────────────────────────────────────\nnew_cols = [c.lower().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"-\", \"_\") for c in df.columns]\ndf_clean = df.toDF(*new_cols)\n\n# ── Transformations ─────────────────────────────────────────────────────────\ndf_clean = (\n    df_clean\n    # Strip BOM / zero-width characters\n    .withColumn(\"event_name\",     regexp_replace(col(\"event_name\"), r\"^[\\ufeff\\u200b]+\", \"\"))\n    .withColumn(\"athlete_country\", upper(trim(col(\"athlete_country\"))))\n    .withColumn(\"athlete_gender\",  upper(trim(col(\"athlete_gender\"))))\n\n    # ── Event date ────────────────────────────────────────────────────────────\n    .withColumn(\"event_date_str\",\n                regexp_extract(col(\"event_dates\"), r\"(\\d{2}\\.\\d{2}\\.\\d{4})\", 1))\n    .withColumn(\"event_start_date\",\n                try_to_date(col(\"event_date_str\"), \"dd.MM.yyyy\"))\n\n    # ── Distance (km and mi) ─────────────────────────────────────────────────\n    .withColumn(\"distance_value\",\n        when(regexp_extract(col(\"event_distance_length\"), r\"(\\d+\\.?\\d*)\", 1) != \"\",\n             regexp_extract(col(\"event_distance_length\"), r\"(\\d+\\.?\\d*)\", 1).cast(DoubleType()))\n        .otherwise(None))\n    .withColumn(\"distance_unit\",\n        when(regexp_extract(col(\"event_distance_length\"), r\"\\d+\\.?\\d*\\s*([a-zA-Z]+)\", 1) != \"\",\n             lower(regexp_extract(col(\"event_distance_length\"), r\"\\d+\\.?\\d*\\s*([a-zA-Z]+)\", 1)))\n        .otherwise(None))\n    .withColumn(\"distance_km\",\n        when(col(\"distance_unit\").isin(\"mi\", \"miles\"), col(\"distance_value\") * 1.60934)\n        .when(col(\"distance_unit\") == \"km\", col(\"distance_value\"))\n        .otherwise(None))\n\n    # ── Performance time (supports multi-day: e.g. '2d 14:22:00') ────────────\n    .withColumn(\"perf_days\",\n        when(regexp_extract(col(\"athlete_performance\"), r\"(\\d+)d\", 1) != \"\",\n             regexp_extract(col(\"athlete_performance\"), r\"(\\d+)d\", 1).cast(IntegerType()))\n        .otherwise(lit(0)))\n    .withColumn(\"perf_time\",\n                regexp_extract(col(\"athlete_performance\"), r\"(\\d{1,2}:\\d{2}:\\d{2})\", 1))\n    .withColumn(\"performance_seconds\",\n        when(col(\"perf_time\") != \"\",\n             col(\"perf_days\") * 86400\n             + split(col(\"perf_time\"), \":\").getItem(0).cast(IntegerType()) * 3600\n             + split(col(\"perf_time\"), \":\").getItem(1).cast(IntegerType()) * 60\n             + split(col(\"perf_time\"), \":\").getItem(2).cast(IntegerType()))\n        .otherwise(None))\n    .withColumn(\"performance_hours\", round(col(\"performance_seconds\") / 3600, 2))\n\n    # ── Athlete age ───────────────────────────────────────────────────────────\n    .withColumn(\"birth_year\",\n        when((col(\"athlete_year_of_birth\") >= 1900) & (col(\"athlete_year_of_birth\") <= 2005),\n             col(\"athlete_year_of_birth\").cast(IntegerType()))\n        .otherwise(None))\n    .withColumn(\"athlete_age\",\n        when(col(\"birth_year\").isNotNull(), col(\"year_of_event\") - col(\"birth_year\"))\n        .otherwise(None))\n\n    # ── Speed (physical ceiling 25 km/h) ─────────────────────────────────────\n    .withColumn(\"avg_speed_kmh\",\n        when(col(\"athlete_average_speed\").rlike(r\"^\\d+\\.?\\d*$\"),\n             col(\"athlete_average_speed\").cast(DoubleType()))\n        .otherwise(None))\n    .withColumn(\"avg_speed_kmh\",\n        when((col(\"avg_speed_kmh\") > 0) & (col(\"avg_speed_kmh\") < 25), col(\"avg_speed_kmh\"))\n        .otherwise(None))\n)\n\n# ── Quality filters ──────────────────────────────────────────────────────────\ndf_filtered = (\n    df_clean\n    .filter(col(\"year_of_event\").between(1950, 2023))\n    .filter((col(\"athlete_age\").isNull()) | col(\"athlete_age\").between(16, 90))\n    .filter(col(\"event_number_of_finishers\") > 0)\n    .filter(col(\"performance_seconds\").isNotNull())\n    .filter(col(\"performance_seconds\") > 0)\n)\n\n# ── Select final columns ─────────────────────────────────────────────────────\ndf_stage1 = df_filtered.select(\n    \"year_of_event\", \"event_start_date\", \"event_name\",\n    col(\"event_distance_length\").alias(\"distance_original\"),\n    \"distance_km\", \"distance_unit\", \"event_number_of_finishers\",\n    \"athlete_id\", \"athlete_gender\", \"athlete_country\",\n    \"birth_year\", \"athlete_age\", \"athlete_age_category\", \"athlete_club\",\n    col(\"athlete_performance\").alias(\"performance_original\"),\n    \"performance_seconds\", \"performance_hours\", \"avg_speed_kmh\"\n)\n\n# ── Save checkpoint ──────────────────────────────────────────────────────────\n# Using toPandas().to_parquet() to avoid Hadoop temp-file permission errors on Windows\ndf_stage1.toPandas().to_parquet(PATHS[\"raw_clean\"])\nprint(f\"Stage 1 saved → {PATHS['raw_clean']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3 · Deduplication\nRemove duplicate athlete–event pairs (one row per `athlete_id` + `event_name`).\n\n> Timing systems sometimes record a runner twice if chip splits were captured separately.  \n> Deduplication keeps the first occurrence, which aligns with the 4.6M figure in the PRD."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = spark.read.parquet(PATHS[\"raw_clean\"])\nprint(f\"Before dedup: {df.count():,} rows\")\n\ndf_dedup = df.dropDuplicates([\"athlete_id\", \"event_name\"])\nprint(f\"After dedup:  {df_dedup.count():,} rows\")\n\ndf_dedup.toPandas().to_parquet(PATHS[\"deduped\"])\nprint(f\"Saved → {PATHS['deduped']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4 · Gender & Null Filtering\n- **Drop `athlete_gender = 'X'`** – non-binary entries represent < 0.1 % of records  \n  and are excluded to maintain consistent M/F comparisons across all dashboard visuals.\n- **Drop null critical columns** – `distance_km`, `avg_speed_kmh`, `performance_seconds`.  \n  Rows missing any of these three cannot contribute to any performance metric."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pyspark.sql.functions import col, sum as _sum\n\ndf = spark.read.parquet(PATHS[\"deduped\"])\n\n# ── Drop 'X' gender ──────────────────────────────────────────────────────────\ndf = df.filter(col(\"athlete_gender\") != \"X\")\nprint(f\"After dropping X gender: {df.count():,} rows\")\ndf.select(\"athlete_gender\").distinct().show()\n\n# ── Null audit ───────────────────────────────────────────────────────────────\naudit_cols = [\"athlete_gender\", \"athlete_age\", \"athlete_country\",\n              \"athlete_club\", \"distance_km\", \"avg_speed_kmh\"]\ndf.select([_sum(col(c).isNull().cast(\"int\")).alias(c) for c in audit_cols]).show()\n\n# ── Drop rows missing critical measures ──────────────────────────────────────\ndf_clean_final = df.dropna(subset=[\"distance_km\", \"avg_speed_kmh\", \"performance_seconds\"])\nprint(f\"After null drop: {df_clean_final.count():,} rows\")\n\n# ── Select and save final clean dataset ─────────────────────────────────────\ndff_spark = df_clean_final.select(\n    \"athlete_id\", \"event_name\", \"distance_km\", \"avg_speed_kmh\",\n    \"athlete_age\", \"athlete_gender\", \"athlete_country\",\n    \"year_of_event\", \"event_start_date\",\n    \"performance_seconds\", \"athlete_club\",\n    \"performance_hours\", \"event_number_of_finishers\"\n)\ndff_spark.toPandas().to_parquet(PATHS[\"final\"])\nprint(f\"Final dataset saved → {PATHS['final']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5 · Exploratory Data Analysis (EDA)\nSwitch to Pandas from here — the heavy lifting is done.\n\n**All helper columns are created once in this setup cell** and reused across every chart,  \neliminating the late-definition bug in the original notebook where `dist_category` was  \nreferenced before it was created in some cells."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\n# ── Load final dataset ───────────────────────────────────────────────────────\ndff = pd.read_parquet(PATHS[\"final\"])\ndff[\"event_start_date\"] = pd.to_datetime(dff[\"event_start_date\"])\n\n# ── Month columns ─────────────────────────────────────────────────────────────\ndff[\"month\"]      = dff[\"event_start_date\"].dt.month_name()   # e.g. 'June'\ndff[\"race_month\"] = dff[\"event_start_date\"].dt.month          # numeric 1-12\n\n# ── Canonical distance bins (Big 4) ──────────────────────────────────────────\ndef bin_distance(dist):\n    \"\"\"Map continuous distance_km to the four canonical ultra distances.\"\"\"\n    if   48  <= dist <= 52:  return \"50km\"\n    elif 78  <= dist <= 82:  return \"50mi (80km)\"\n    elif 98  <= dist <= 102: return \"100km\"\n    elif 158 <= dist <= 165: return \"100mi (160km)\"\n    return \"Other\"\n\ndff[\"dist_category\"] = dff[\"distance_km\"].apply(bin_distance)\n\n# ── Elite tier  (PRD §5 – 90th percentile per gender × distance) ─────────────\n# Elite = top-10% speed within each gender AND distance group.\n# This mirrors the methodology in agg_elite_vs_avg powering the Performance Lab.\ndff[\"speed_90th\"] = (\n    dff.groupby([\"athlete_gender\", \"distance_km\"])[\"avg_speed_kmh\"]\n    .transform(lambda x: x.quantile(0.90))\n)\ndff[\"athlete_tier\"] = np.where(\n    dff[\"avg_speed_kmh\"] >= dff[\"speed_90th\"], \"Elite\", \"Average\"\n)\n\nprint(f\"Loaded {len(dff):,} rows | {dff['year_of_event'].min()}–{dff['year_of_event'].max()}\")\nprint(\"Gender:\",  dff[\"athlete_gender\"].value_counts().to_dict())\nprint(\"Tier:\",    dff[\"athlete_tier\"].value_counts().to_dict())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5.1 · Overview Dashboard – Age, Speed, Seasonality, Pace Decay"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "MONTH_ORDER = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\n               \"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\nMAIN_DIST   = [\"50km\", \"50mi (80km)\", \"100km\", \"100mi (160km)\"]\n\nfig, axes = plt.subplots(2, 2, figsize=(18, 12))\nfig.suptitle(\"Ultra-Marathon EDA Dashboard: Who, When, and How Fast?\", fontsize=20)\n\n# Age distribution by gender\nsns.histplot(data=dff, x=\"athlete_age\", hue=\"athlete_gender\", bins=30, kde=True,\n             palette={\"M\": \"#3498db\", \"F\": \"#e74c3c\"}, ax=axes[0, 0])\naxes[0, 0].set_title(\"Distribution of Runner Ages\", fontsize=14)\naxes[0, 0].set_xlim(18, 80)\n\n# Speed distribution\nmean_speed = dff[\"avg_speed_kmh\"].mean()\nsns.histplot(data=dff, x=\"avg_speed_kmh\", bins=30, color=\"green\", kde=True, ax=axes[0, 1])\naxes[0, 1].axvline(mean_speed, color=\"red\", linestyle=\"--\",\n                   label=f\"Mean: {mean_speed:.1f} km/h\")\naxes[0, 1].set_title(\"Distribution of Average Speed\", fontsize=14)\naxes[0, 1].legend()\n\n# Seasonality\nsns.countplot(data=dff, x=\"month\", order=MONTH_ORDER, palette=\"viridis\", ax=axes[1, 0])\naxes[1, 0].set_title(\"Seasonality: Which Months Are Most Popular?\", fontsize=14)\naxes[1, 0].tick_params(axis=\"x\", rotation=45)\n\n# Pace decay\nsubset_dist = dff[dff[\"dist_category\"].isin(MAIN_DIST)]\nsns.boxplot(data=subset_dist, x=\"dist_category\", y=\"avg_speed_kmh\",\n            order=MAIN_DIST, palette=\"magma\", ax=axes[1, 1])\naxes[1, 1].set_title(\"Pace Decay: How Speed Drops with Distance\", fontsize=14)\n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5.2 · Elite vs Average – Age Profile & Pace Decay"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "palette = {\"Elite\": \"#e74c3c\", \"Average\": \"#95a5a6\"}\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Age profile\nsns.kdeplot(data=dff, x=\"athlete_age\", hue=\"athlete_tier\", fill=True,\n            palette=palette, alpha=0.3, ax=axes[0])\naxes[0].set_title(\"Age Profile: Do You Have to Be Young to Be Elite?\", fontsize=14)\naxes[0].set_xlim(18, 70)\n\n# Pace decay by tier\nsubset_dist = dff[dff[\"dist_category\"].isin(MAIN_DIST)]\nsns.pointplot(data=subset_dist, x=\"dist_category\", y=\"avg_speed_kmh\", hue=\"athlete_tier\",\n              order=MAIN_DIST, palette=palette,\n              markers=[\"o\", \"x\"], linestyles=[\"-\", \"--\"], ax=axes[1])\naxes[1].set_title(\"Pace Decay – Elite vs Average\", fontsize=14)\n\nplt.tight_layout()\nplt.show()\n\n# Elite threshold summary\nfor gender in [\"M\", \"F\"]:\n    threshold = dff[dff[\"athlete_gender\"] == gender][\"avg_speed_kmh\"].quantile(0.90)\n    label = \"Male\" if gender == \"M\" else \"Female\"\n    print(f\"Elite threshold ({label}): > {threshold:.2f} km/h  (90th percentile)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5.3 · The Ultra-Running Boom (1996–2022)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "growth = (\n    dff[dff[\"year_of_event\"] >= 1996]\n    .groupby(\"year_of_event\")\n    .agg(Total_Finishers=(\"athlete_id\", \"count\"),\n         Unique_Events=(\"event_name\", \"nunique\"))\n    .sort_index()\n)\n\nfig, ax1 = plt.subplots(figsize=(14, 6))\nax1.bar(growth.index, growth[\"Total_Finishers\"], alpha=0.6, color=\"royalblue\")\nax1.set_ylabel(\"Number of Finishers\", color=\"royalblue\", fontsize=12)\nax1.tick_params(axis=\"y\", labelcolor=\"royalblue\")\nax1.set_xlabel(\"Year\", fontsize=12)\n\nax2 = ax1.twinx()\nax2.plot(growth.index, growth[\"Unique_Events\"],\n         color=\"crimson\", marker=\"o\", linewidth=2)\nax2.set_ylabel(\"Number of Races\", color=\"crimson\", fontsize=12)\nax2.tick_params(axis=\"y\", labelcolor=\"crimson\")\n\n# COVID-19 annotation\nax1.axvline(2020, color=\"black\", linestyle=\":\", alpha=0.6)\nax1.text(2020.2, ax1.get_ylim()[1] * 0.9, \"COVID-19\", fontsize=9)\n\nplt.title(\"Ultra-Marathon Growth (1996–2022)\", fontsize=16, pad=20)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5.4 · Rise of Female Ultra Runners"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "gender_growth = (\n    dff[dff[\"year_of_event\"] >= 1996]\n    .groupby([\"year_of_event\", \"athlete_gender\"])\n    .size().reset_index(name=\"count\")\n)\ngender_pivot = (\n    gender_growth\n    .pivot(index=\"year_of_event\", columns=\"athlete_gender\", values=\"count\")\n    .fillna(0)\n)\ngender_pivot[\"Total\"]      = gender_pivot[\"M\"] + gender_pivot[\"F\"]\ngender_pivot[\"Female_Pct\"] = gender_pivot[\"F\"] / gender_pivot[\"Total\"] * 100\n\nfig, ax1 = plt.subplots(figsize=(14, 7))\nsns.lineplot(data=gender_growth, x=\"year_of_event\", y=\"count\", hue=\"athlete_gender\",\n             palette={\"M\": \"#3498db\", \"F\": \"#e74c3c\"}, linewidth=2.5, ax=ax1)\nax1.set_ylabel(\"Number of Runners\", fontsize=12)\nax1.legend(title=\"Gender\", loc=\"upper left\")\n\nax2 = ax1.twinx()\nax2.fill_between(gender_pivot.index, gender_pivot[\"Female_Pct\"],\n                 color=\"#e74c3c\", alpha=0.15)\nax2.plot(gender_pivot.index, gender_pivot[\"Female_Pct\"],\n         color=\"#e74c3c\", linestyle=\"--\", linewidth=1.5, alpha=0.6)\nax2.set_ylabel(\"Female Participation (%)\", color=\"#c0392b\", fontsize=12)\nax2.set_ylim(0, 40)\nax2.tick_params(axis=\"y\", labelcolor=\"#c0392b\")\n\nlatest = gender_pivot.index.max()\nax2.text(latest + 0.3, gender_pivot.loc[latest, \"Female_Pct\"],\n         f\"{gender_pivot.loc[latest, 'Female_Pct']:.1f}%\",\n         color=\"#c0392b\", fontweight=\"bold\")\n\nplt.title(\"Rise of Female Ultra Runners (1996–2022)\", fontsize=16, pad=20)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5.5 · Peak Age Curve (50 km races)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "subset_50 = dff[\n    (dff[\"distance_km\"] == 50)\n    & (dff[\"athlete_age\"].between(18, 70))\n    & (dff[\"athlete_gender\"].isin([\"M\", \"F\"]))\n]\n\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=subset_50, x=\"athlete_age\", y=\"avg_speed_kmh\",\n             hue=\"athlete_gender\", palette=[\"#1f77b4\", \"#ff7f0e\"])\nplt.title(\"At What Age Are Ultra Runners Fastest? (50 km Races)\", fontsize=16)\nplt.xlabel(\"Athlete Age\")\nplt.ylabel(\"Average Speed (km/h)\")\nplt.grid(True, alpha=0.3)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6 · Star-Schema Export\nGenerates the **V1 Analytics-First Model** tables consumed by Power BI.\n\n| Table | Grain | Power BI relationship |\n|---|---|---|\n| `dim_athletes` | One row per athlete | `athlete_id` → `fact_races` |\n| `dim_events` | One row per event–distance | `event_name` → `fact_races` |\n| `dim_date` | One row per calendar day (1950–2022) | `full_date` → `fact_races.event_start_date` |\n| `dim_distance` | Four canonical distances | `distance_km` → `fact_races` |\n| `dim_gender` | M / F | `athlete_gender` → `dim_athletes` |\n| `fact_races` | One row per athlete performance | central fact |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── dim_athletes ──────────────────────────────────────────────────────────────\n# Note: birth_year is self-reported and may contain errors (PRD §6)\ndim_athletes = dff[[\"athlete_id\", \"athlete_gender\", \"athlete_country\"]].drop_duplicates()\ndim_athletes.to_csv(PATHS[\"dim_athletes\"], index=False)\nprint(f\"dim_athletes : {dim_athletes.shape}\")\n\n# ── dim_events ────────────────────────────────────────────────────────────────\n# Note: distance_km is the reported distance; actual course lengths vary by terrain (PRD §6)\ndim_events = dff[[\"event_name\", \"distance_km\"]].drop_duplicates()\ndim_events.to_csv(PATHS[\"dim_events\"], index=False)\nprint(f\"dim_events   : {dim_events.shape}\")\n\n# ── dim_date (full calendar 1950–2022) ───────────────────────────────────────\ndate_range = pd.date_range(start=\"1950-01-01\", end=\"2022-12-31\", freq=\"D\")\ndim_date = pd.DataFrame({\"full_date\": date_range})\ndim_date[\"year\"]         = dim_date[\"full_date\"].dt.year\ndim_date[\"quarter\"]      = dim_date[\"full_date\"].dt.quarter\ndim_date[\"month\"]        = dim_date[\"full_date\"].dt.month\ndim_date[\"month_name\"]   = dim_date[\"full_date\"].dt.month_name()\ndim_date[\"day_of_week\"]  = dim_date[\"full_date\"].dt.dayofweek + 1  # 1=Mon, 7=Sun (ISO)\ndim_date[\"week_of_year\"] = dim_date[\"full_date\"].dt.isocalendar().week\ndim_date.to_csv(PATHS[\"dim_date\"], index=False)\nprint(f\"dim_date     : {dim_date.shape}\")\n\n# ── dim_distance (Big 4) ──────────────────────────────────────────────────────\ndim_distance = pd.DataFrame([\n    (50.0,    \"50km\",  \"Short Ultra\", \"Standard\"),\n    (80.467,  \"50mi\",  \"Short Ultra\", \"Standard\"),\n    (100.0,   \"100km\", \"Long Ultra\",  \"Standard\"),\n    (160.934, \"100mi\", \"Long Ultra\",  \"Standard\"),\n], columns=[\"distance_km\", \"distance_name\", \"distance_category\", \"distance_type\"])\ndim_distance.to_csv(PATHS[\"dim_distance\"], index=False)\nprint(f\"dim_distance : {dim_distance.shape}\")\n\n# ── dim_gender ────────────────────────────────────────────────────────────────\ndim_gender = pd.DataFrame(\n    [(\"M\", \"Male\"), (\"F\", \"Female\")],\n    columns=[\"athlete_gender\", \"gender_full_name\"]\n)\ndim_gender.to_csv(PATHS[\"dim_gender\"], index=False)\nprint(f\"dim_gender   : {dim_gender.shape}\")\n\n# ── fact_races ────────────────────────────────────────────────────────────────\nfact_races = dff[[\n    \"athlete_id\", \"event_name\", \"event_start_date\", \"distance_km\",\n    \"performance_seconds\", \"avg_speed_kmh\", \"athlete_age\"\n]].drop_duplicates()\nfact_races.to_parquet(PATHS[\"fact_races\"], index=False)\nprint(f\"fact_races   : {fact_races.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7 · Pre-Aggregated Tables for Power BI\nPre-computing these aggregations in Python ensures Power BI loads within  \nthe **< 3 s** target defined in PRD §4 Success Metrics.\n\n| Table | Powers visual |\n|---|---|\n| `agg_yearly` | Global Growth Hub – dual-axis growth chart |\n| `agg_country` | Global Growth Hub – top countries bar chart |\n| `agg_seasonality` | Performance Lab – seasonality heatmap |\n| `agg_age_performance` | Performance Lab – Peak Age Curve |\n| `agg_elite_vs_avg` | Performance Lab – Pace Decay & Pain Cave Benchmarks |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── AGG 1: Yearly ─────────────────────────────────────────────────────────────\nagg_yearly = (\n    dff.groupby([\"year_of_event\", \"athlete_gender\", \"distance_km\"])\n    .agg(total_finishers=(\"athlete_id\", \"count\"),\n         total_races=(\"event_name\", \"nunique\"),\n         avg_speed=(\"avg_speed_kmh\", \"mean\"),\n         avg_age=(\"athlete_age\", \"mean\"))\n    .reset_index()\n    .sort_values(\"year_of_event\")\n)\nagg_yearly.to_csv(PATHS[\"agg_yearly\"], index=False)\nprint(f\"agg_yearly        : {agg_yearly.shape}\")\n\n# ── AGG 2: Country ────────────────────────────────────────────────────────────\nagg_country = (\n    dff.groupby([\"athlete_country\", \"year_of_event\"])\n    .agg(total_finishers=(\"athlete_id\", \"count\"))\n    .reset_index()\n    .sort_values(\"total_finishers\", ascending=False)\n)\nagg_country.to_csv(PATHS[\"agg_country\"], index=False)\nprint(f\"agg_country       : {agg_country.shape}\")\n\n# ── AGG 3: Monthly Seasonality ────────────────────────────────────────────────\nagg_seasonality = (\n    dff.groupby([\"race_month\", \"distance_km\"])\n    .agg(race_count=(\"athlete_id\", \"count\"))\n    .reset_index()\n    .sort_values(\"race_month\")\n)\nagg_seasonality.to_csv(PATHS[\"agg_seasonal\"], index=False)\nprint(f\"agg_seasonality   : {agg_seasonality.shape}\")\n\n# ── AGG 4: Age Performance (n > 10 filter for statistical significance) ────────\nagg_age = (\n    dff.groupby([\"athlete_age\", \"athlete_gender\", \"distance_km\"])\n    .agg(avg_speed=(\"avg_speed_kmh\", \"mean\"),\n         sample_size=(\"athlete_id\", \"count\"))\n    .reset_index()\n    .query(\"sample_size > 10\")\n)\nagg_age.to_csv(PATHS[\"agg_age\"], index=False)\nprint(f\"agg_age_perf      : {agg_age.shape}\")\n\n# ── AGG 5: Elite vs Average (PRD §5 – 90th percentile per gender × distance) ──\nagg_elite = (\n    dff.groupby([\"distance_km\", \"athlete_gender\", \"athlete_tier\"])\n    .agg(avg_speed=(\"avg_speed_kmh\", \"mean\"),\n         total_athletes=(\"athlete_id\", \"count\"))\n    .reset_index()\n)\nagg_elite.to_csv(PATHS[\"agg_elite\"], index=False)\nprint(f\"agg_elite_vs_avg  : {agg_elite.shape}\")\n\nprint(\"\\n✅ All pre-aggregated tables saved successfully.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Appendix · Memory Optimisation Reference\nApply these dtype casts to the final Pandas DataFrame before export if RAM is constrained.  \nReduces fact-table in-memory footprint by ~40 %.\n\n| Column | Original | Optimised | Reason |\n|---|---|---|---|\n| `athlete_id` | int64 | int32 | IDs ≤ 2 B |\n| `year_of_event` | int64 | int16 | Years ≤ 32 K |\n| `athlete_age` | float64 | int8 | Ages ≤ 127; nulls → 0 |\n| `distance_km` | float64 | float32 | Precision preserved |\n| `avg_speed_kmh` | float64 | float32 | Precision preserved |\n| `performance_seconds` | int64 | int32 | Handles up to ~68 years |\n| `athlete_gender` | object | category | 2 unique values |\n| `athlete_country` | object | category | ~100 unique values |\n\n```python\nimport numpy as np\ndf_final = dff.copy()\ndf_final[\"athlete_id\"]          = df_final[\"athlete_id\"].astype(\"int32\")\ndf_final[\"year_of_event\"]       = df_final[\"year_of_event\"].astype(\"int16\")\ndf_final[\"athlete_age\"]         = df_final[\"athlete_age\"].fillna(0).astype(\"int8\")\ndf_final[\"distance_km\"]         = df_final[\"distance_km\"].astype(\"float32\")\ndf_final[\"avg_speed_kmh\"]       = df_final[\"avg_speed_kmh\"].astype(\"float32\")\ndf_final[\"performance_seconds\"] = df_final[\"performance_seconds\"].astype(\"int32\")\ndf_final[\"athlete_gender\"]      = df_final[\"athlete_gender\"].astype(\"category\")\ndf_final[\"athlete_country\"]     = df_final[\"athlete_country\"].astype(\"category\")\n```"
  }
 ]
}